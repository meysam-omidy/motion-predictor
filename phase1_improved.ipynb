{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d78f505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 15072, Val samples: 28163\n"
     ]
    }
   ],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "SEQ_IN_LEN = 30\n",
    "SEQ_OUT_LEN = 20\n",
    "SEQ_TOTAL_LEN = 50\n",
    "BATCH_SIZE = 1024\n",
    "STEPS = 4\n",
    "NOISE_COEFFICIENT = 0\n",
    "NOISE_PROB = 0\n",
    "NOISE_COEFFICIENT = 0.15\n",
    "NOISE_PROB = 0.2\n",
    "\n",
    "BASE_DIR = '../../Datasets/'\n",
    "# train_dataset = ConcatDataset([\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}DanceTrack/train'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT20/train'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT17/train'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "# ])\n",
    "# val_dataset = ConcatDataset([\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}DanceTrack/val'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT20/val'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT17/val'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "# ])\n",
    "train_dataset = GTSequenceDataset.from_roots([\n",
    "    # f'{BASE_DIR}/SportsMOT/train',\n",
    "    # f'{BASE_DIR}DanceTrack/train',\n",
    "    f'{BASE_DIR}MOT17/train',\n",
    "    # f'{BASE_DIR}MOT20/train'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB)\n",
    "\n",
    "val_dataset = GTSequenceDataset.from_roots([\n",
    "    # f'{BASE_DIR}/SportsMOT/val',\n",
    "    # f'{BASE_DIR}DanceTrack/val',\n",
    "    f'{BASE_DIR}MOT17/val',\n",
    "    # f'{BASE_DIR}MOT20/val'\n",
    "# ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=0, noise_prob=0)\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16503064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 1,911,813\n",
      "Epoch 1: Train Loss = 0.60551686, Val Loss = 0.17987538, LR = 0.00049976\n",
      "Epoch 2: Train Loss = 0.19389952, Val Loss = 0.10858391, LR = 0.00049902\n",
      "Epoch 3: Train Loss = 0.13091740, Val Loss = 0.09556698, LR = 0.00049780\n",
      "Epoch 4: Train Loss = 0.10724405, Val Loss = 0.08109847, LR = 0.00049609\n",
      "Epoch 5: Train Loss = 0.08804472, Val Loss = 0.07756049, LR = 0.00049391\n",
      "Epoch 6: Train Loss = 0.07673899, Val Loss = 0.07491766, LR = 0.00049124\n",
      "Epoch 7: Train Loss = 0.06828707, Val Loss = 0.06553560, LR = 0.00048810\n",
      "Epoch 8: Train Loss = 0.06297994, Val Loss = 0.06697503, LR = 0.00048450\n",
      "Epoch 9: Train Loss = 0.05983980, Val Loss = 0.06417410, LR = 0.00048044\n",
      "Epoch 10: Train Loss = 0.06022786, Val Loss = 0.07111049, LR = 0.00047592\n",
      "Epoch 11: Train Loss = 0.06114988, Val Loss = 0.06295310, LR = 0.00047097\n",
      "Epoch 12: Train Loss = 0.05478626, Val Loss = 0.06045165, LR = 0.00046558\n",
      "Epoch 13: Train Loss = 0.05296187, Val Loss = 0.05958388, LR = 0.00045977\n",
      "Epoch 14: Train Loss = 0.05181371, Val Loss = 0.05855078, LR = 0.00045355\n",
      "Epoch 15: Train Loss = 0.05179015, Val Loss = 0.05782353, LR = 0.00044693\n",
      "Epoch 16: Train Loss = 0.04990907, Val Loss = 0.05763787, LR = 0.00043992\n",
      "Epoch 17: Train Loss = 0.04927518, Val Loss = 0.05654321, LR = 0.00043254\n",
      "Epoch 18: Train Loss = 0.04881573, Val Loss = 0.05656774, LR = 0.00042481\n",
      "Epoch 19: Train Loss = 0.04840563, Val Loss = 0.05585770, LR = 0.00041673\n",
      "Epoch 20: Train Loss = 0.04797542, Val Loss = 0.05558841, LR = 0.00040833\n",
      "Epoch 21: Train Loss = 0.04760704, Val Loss = 0.05490130, LR = 0.00039962\n",
      "Epoch 22: Train Loss = 0.04725069, Val Loss = 0.05440773, LR = 0.00039061\n",
      "Epoch 23: Train Loss = 0.04677585, Val Loss = 0.05399465, LR = 0.00038133\n",
      "Epoch 24: Train Loss = 0.04654611, Val Loss = 0.05412288, LR = 0.00037179\n",
      "Epoch 25: Train Loss = 0.04623465, Val Loss = 0.05556329, LR = 0.00036202\n",
      "Epoch 26: Train Loss = 0.04610639, Val Loss = 0.05323722, LR = 0.00035202\n",
      "Epoch 27: Train Loss = 0.04583413, Val Loss = 0.05382893, LR = 0.00034183\n",
      "Epoch 28: Train Loss = 0.04564878, Val Loss = 0.05273969, LR = 0.00033145\n",
      "Epoch 29: Train Loss = 0.04541886, Val Loss = 0.05271664, LR = 0.00032092\n",
      "Epoch 30: Train Loss = 0.04521701, Val Loss = 0.05241332, LR = 0.00031024\n",
      "Epoch 31: Train Loss = 0.04508620, Val Loss = 0.05278704, LR = 0.00029945\n",
      "Epoch 32: Train Loss = 0.04491133, Val Loss = 0.05207627, LR = 0.00028856\n",
      "Epoch 33: Train Loss = 0.04481294, Val Loss = 0.05220139, LR = 0.00027760\n",
      "Epoch 34: Train Loss = 0.04457087, Val Loss = 0.05246882, LR = 0.00026658\n",
      "Epoch 35: Train Loss = 0.04446866, Val Loss = 0.05219496, LR = 0.00025553\n",
      "Training complete. Best Val Loss: 0.05207627280442803\n",
      "Epoch 1: Train Loss = 0.06931826, Val Loss = 0.05046115, LR = 0.00024447\n",
      "Epoch 2: Train Loss = 0.04875720, Val Loss = 0.04585696, LR = 0.00023342\n",
      "Epoch 3: Train Loss = 0.04539589, Val Loss = 0.04358732, LR = 0.00022240\n",
      "Epoch 4: Train Loss = 0.04348921, Val Loss = 0.04186333, LR = 0.00021144\n",
      "Epoch 5: Train Loss = 0.04216960, Val Loss = 0.04107071, LR = 0.00020055\n",
      "Epoch 6: Train Loss = 0.04126104, Val Loss = 0.04051684, LR = 0.00018976\n",
      "Epoch 7: Train Loss = 0.04048301, Val Loss = 0.03999676, LR = 0.00017908\n",
      "Epoch 8: Train Loss = 0.03990022, Val Loss = 0.03988702, LR = 0.00016855\n",
      "Epoch 9: Train Loss = 0.03940009, Val Loss = 0.03917980, LR = 0.00015817\n",
      "Epoch 10: Train Loss = 0.03901500, Val Loss = 0.03935707, LR = 0.00014798\n",
      "Epoch 11: Train Loss = 0.03862323, Val Loss = 0.03877474, LR = 0.00013798\n",
      "Epoch 12: Train Loss = 0.03829880, Val Loss = 0.03838827, LR = 0.00012821\n",
      "Epoch 13: Train Loss = 0.03803771, Val Loss = 0.03889145, LR = 0.00011867\n",
      "Epoch 14: Train Loss = 0.03782795, Val Loss = 0.03854065, LR = 0.00010939\n",
      "Epoch 15: Train Loss = 0.03760328, Val Loss = 0.03837292, LR = 0.00010038\n",
      "Training complete. Best Val Loss: 0.03837291761818859\n",
      "Epoch 1: Train Loss = 0.05650545, Val Loss = 0.05582738, LR = 0.00009167\n",
      "Epoch 2: Train Loss = 0.05546918, Val Loss = 0.05409547, LR = 0.00008327\n",
      "Epoch 3: Train Loss = 0.05489445, Val Loss = 0.05417601, LR = 0.00007519\n",
      "Epoch 4: Train Loss = 0.05443200, Val Loss = 0.05325984, LR = 0.00006746\n",
      "Epoch 5: Train Loss = 0.05407898, Val Loss = 0.05325386, LR = 0.00006008\n",
      "Epoch 6: Train Loss = 0.05376754, Val Loss = 0.05248506, LR = 0.00005307\n",
      "Epoch 7: Train Loss = 0.05352351, Val Loss = 0.05222878, LR = 0.00004645\n",
      "Epoch 8: Train Loss = 0.05329188, Val Loss = 0.05163342, LR = 0.00004023\n",
      "Epoch 9: Train Loss = 0.05310255, Val Loss = 0.05203888, LR = 0.00003442\n",
      "Epoch 10: Train Loss = 0.05294546, Val Loss = 0.05177076, LR = 0.00002903\n",
      "Training complete. Best Val Loss: 0.05163342088322948\n",
      "Epoch 1: Train Loss = 0.07207721, Val Loss = 0.06826028, LR = 0.00002408\n",
      "Epoch 2: Train Loss = 0.07141035, Val Loss = 0.06819539, LR = 0.00001956\n",
      "Epoch 3: Train Loss = 0.07110453, Val Loss = 0.06738362, LR = 0.00001550\n",
      "Epoch 4: Train Loss = 0.07090091, Val Loss = 0.06732439, LR = 0.00001190\n",
      "Epoch 5: Train Loss = 0.07075694, Val Loss = 0.06740847, LR = 0.00000876\n",
      "Epoch 6: Train Loss = 0.07066243, Val Loss = 0.06715518, LR = 0.00000609\n",
      "Epoch 7: Train Loss = 0.07059356, Val Loss = 0.06731775, LR = 0.00000391\n",
      "Epoch 8: Train Loss = 0.07051640, Val Loss = 0.06730103, LR = 0.00000220\n",
      "Epoch 9: Train Loss = 0.07050733, Val Loss = 0.06725289, LR = 0.00000098\n",
      "Epoch 10: Train Loss = 0.07048006, Val Loss = 0.06725070, LR = 0.00000024\n",
      "Training complete. Best Val Loss: 0.0671551832239385\n"
     ]
    }
   ],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from transformer_encoder import MotionTransformer\n",
    "from loss import LossFunction\n",
    "from torch import optim\n",
    "import math, torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "SEQ_IN_LEN = 30\n",
    "SEQ_OUT_LEN = 20\n",
    "SEQ_TOTAL_LEN = 50\n",
    "BATCH_SIZE = 1024\n",
    "STEPS = 4\n",
    "NOISE_COEFFICIENT = 0\n",
    "NOISE_PROB = 0\n",
    "NOISE_COEFFICIENT = 0.15\n",
    "LR = 5e-4\n",
    "DEVICE = 'cuda'\n",
    "PARAMS = [[35, 0], [15, 0.2], [10, 0.4], [10, 0.6]]\n",
    "\n",
    "model = MotionTransformer(\n",
    "    input_dim=13,\n",
    "    output_dim=5,\n",
    "    # d_model=128,\n",
    "    d_model=512,\n",
    "    # nhead=16,\n",
    "    nhead=32,\n",
    "    num_layers=1,\n",
    "    dim_ff=512,\n",
    "    dropout=0.15,\n",
    ").to(DEVICE)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=1e-4,\n",
    "    eps=1e-8\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=sum([p[0] for p in PARAMS]) + 1)\n",
    "\n",
    "log_file = open('file.log', 'w')\n",
    "log_file.close()\n",
    "# NOISE_PROB = 0.2\n",
    "\n",
    "for param in PARAMS:\n",
    "    NUM_EPOCHS, NOISE_PROB = param\n",
    "    if NOISE_PROB > 0:\n",
    "        criterion = LossFunction(loss1_coeff=0.5, loss2_coeff=0, loss3_coeff=1, loss4_coeff=0)\n",
    "    else:\n",
    "        criterion = LossFunction(loss1_coeff=1, loss2_coeff=0, loss3_coeff=0, loss4_coeff=0)\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    BASE_DIR = '../../Datasets/'\n",
    "    train_dataset = GTSequenceDataset.from_roots([\n",
    "        f'{BASE_DIR}/SportsMOT/train',\n",
    "        f'{BASE_DIR}DanceTrack/train',\n",
    "        f'{BASE_DIR}MOT17/train',\n",
    "        f'{BASE_DIR}MOT20/train'\n",
    "    ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB)\n",
    "    val_dataset = GTSequenceDataset.from_roots([\n",
    "        f'{BASE_DIR}/SportsMOT/val',\n",
    "        f'{BASE_DIR}DanceTrack/val',\n",
    "        f'{BASE_DIR}MOT17/val',\n",
    "        f'{BASE_DIR}MOT20/val'\n",
    "    # ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=0, noise_prob=0)\n",
    "    ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        train_loss = model.train_one_epoch(train_loader, optimizer, criterion)\n",
    "        val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weight('pretrained/transformer-encoder-d256-ff512-nh32-1l-n3.pth')\n",
    "            # model.save_weight('pretrained/transformer-encoder-d512-ff512-2l.pth')\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "        log_file = open('file.log', 'a')\n",
    "        log_file.write(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\\n\")\n",
    "        log_file.close()\n",
    "\n",
    "    print(\"Training complete. Best Val Loss:\", best_val_loss)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1949135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 3,247,621\n"
     ]
    }
   ],
   "source": [
    "from transformer_encoder import MotionTransformer\n",
    "from loss import LossFunction\n",
    "from torch import optim\n",
    "import math, torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "model = MotionTransformer(\n",
    "    input_dim=13,\n",
    "    output_dim=5,\n",
    "    d_model=256,\n",
    "    # d_model=512,\n",
    "    # nhead=16,\n",
    "    nhead=32,\n",
    "    num_layers=6,\n",
    "    dim_ff=512,\n",
    "    dropout=0.15,\n",
    ").to(DEVICE)\n",
    "criterion = LossFunction(loss1_coeff=1, loss2_coeff=0, loss3_coeff=0, loss4_coeff=0)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71acf36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4bb7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weight('pretrained/transformer-encoder-d256-ff512-nh32-1l-n3.pth')\n",
    "# model.load_weight('pretrained/transformer-encoder-d256-ff512-nh32-1l-n.pth')\n",
    "# model.load_weight('pretrained/transformer-encoder-d256-ff512-2l.pth')\n",
    "# model.load_weight('pretrained/transformer-encoder-d256-ff512-6l-ft.pth')\n",
    "# model.load_weight('pretrained/transformer-encoder-d512-ff512-2l-ft.pth')\n",
    "# model.load_weight('pretrained/transformer-encoder-d512-ff512-6l.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6200b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16076720340384376"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e0d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = LossFunction(loss1_coeff=1, loss2_coeff=0, loss3_coeff=0, loss4_coeff=0)\n",
    "# criterion2 = LossFunction(loss1_coeff=0, loss2_coeff=0, loss3_coeff=0, loss4_coeff=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64158207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057145387296461396"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_loader, criterion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d719e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.17073468, Val Loss = 0.15598132, LR = 0.00000994\n",
      "Epoch 2: Train Loss = 0.16916021, Val Loss = 0.15502857, LR = 0.00000978\n",
      "Epoch 3: Train Loss = 0.16823071, Val Loss = 0.15454584, LR = 0.00000950\n",
      "Epoch 4: Train Loss = 0.16758093, Val Loss = 0.15407908, LR = 0.00000913\n",
      "Epoch 5: Train Loss = 0.16697631, Val Loss = 0.15332996, LR = 0.00000867\n",
      "Epoch 6: Train Loss = 0.16642478, Val Loss = 0.15303068, LR = 0.00000812\n",
      "Epoch 7: Train Loss = 0.16596075, Val Loss = 0.15237219, LR = 0.00000750\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-5\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=1e-4,\n",
    "    eps=1e-8\n",
    ")\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#         optimizer,\n",
    "#         mode='min',\n",
    "#         factor=0.5,\n",
    "#         patience= 11,  # Reduce LR before early stopping\n",
    "#         verbose=True,\n",
    "#         min_lr=LR * 0.001\n",
    "#     )\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS + 1)\n",
    "best_val_loss = float(\"inf\")\n",
    "log_file = open('file.log', 'w')\n",
    "log_file.close()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss = model.train_one_epoch(train_loader, optimizer, criterion)\n",
    "    val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model.save_weight('pretrained/transformer-encoder-d256-ff512-nh32-1l-n3.pth')\n",
    "        # model.save_weight('pretrained/transformer-encoder-d512-ff512-2l.pth')\n",
    "\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "    log_file = open('file.log', 'a')\n",
    "    log_file.write(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\\n\")\n",
    "    log_file.close()\n",
    "\n",
    "print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "585d77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open('file.log', 'w')\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c9b8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weight('pretrained/transformer-encoder-d128-ff512-nh32-1l.pth')\n",
    "# model.save_weight('pretrained/transformer-encoder-d256-ff512-2l-n2.pth')\n",
    "# model.load_weight('pretrained/transformer-encoder-d512-ff512-2l-.pth')\n",
    "# model.load_weight('pretrained/transformer-encoder-d256-ff512-2l-test2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd017171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b, c, d = next(iter(train_loader))\n",
    "a, b, c, d = next(iter(val_loader))\n",
    "a = a.cuda()\n",
    "b = b.cuda()\n",
    "c = c.cuda()\n",
    "d = d.cuda()\n",
    "o = model.forward(a, b[:, :-1])[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "603cb006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8831, 0.8832, 0.8835, 0.8836, 0.8837, 0.8836, 0.8832, 0.8830, 0.8832,\n",
       "        0.8832, 0.8834, 0.8835, 0.8830, 0.8827, 0.8824, 0.8824, 0.8829, 0.8831,\n",
       "        0.8833], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d3c713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8621]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.tensor([[[0.1976, 0.0841, 0.0298, 0.0943]]]).cuda()\n",
    "h = torch.tensor([[[0.1991, 0.0818, 0.0281, 0.0977]]]).cuda()\n",
    "\n",
    "criterion.iou(g, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ead765a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mdiagonal(criterion\u001b[38;5;241m.\u001b[39miou(d[:, :, :\u001b[38;5;241m4\u001b[39m], \u001b[43mo\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m), dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "torch.diagonal(criterion.iou(d[:, :, :4], o[:, :, :4]), dim1=1, dim2=2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2939eabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8457, 0.0280, 0.0290, 0.0544],\n",
       "        [0.8457, 0.0280, 0.0290, 0.0544],\n",
       "        [0.8457, 0.0285, 0.0290, 0.0555],\n",
       "        [0.8457, 0.0285, 0.0290, 0.0555],\n",
       "        [0.8457, 0.0285, 0.0290, 0.0555],\n",
       "        [0.8457, 0.0291, 0.0290, 0.0566],\n",
       "        [0.8457, 0.0291, 0.0290, 0.0566],\n",
       "        [0.8457, 0.0291, 0.0290, 0.0567],\n",
       "        [0.8457, 0.0297, 0.0290, 0.0578],\n",
       "        [0.8453, 0.0297, 0.0281, 0.0578],\n",
       "        [0.8457, 0.0297, 0.0273, 0.0578],\n",
       "        [0.8457, 0.0297, 0.0273, 0.0578],\n",
       "        [0.8461, 0.0297, 0.0264, 0.0578],\n",
       "        [0.8466, 0.0302, 0.0256, 0.0589],\n",
       "        [0.8466, 0.0302, 0.0256, 0.0589],\n",
       "        [0.8470, 0.0302, 0.0247, 0.0589],\n",
       "        [0.8470, 0.0303, 0.0247, 0.0589],\n",
       "        [0.8474, 0.0303, 0.0239, 0.0589],\n",
       "        [0.8478, 0.0308, 0.0230, 0.0601]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52090d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8457, 0.0284, 0.0290, 0.0545],\n",
       "        [0.8457, 0.0290, 0.0290, 0.0557],\n",
       "        [0.8457, 0.0290, 0.0290, 0.0557],\n",
       "        [0.8457, 0.0290, 0.0290, 0.0557],\n",
       "        [0.8457, 0.0295, 0.0290, 0.0568],\n",
       "        [0.8457, 0.0295, 0.0290, 0.0568],\n",
       "        [0.8457, 0.0295, 0.0290, 0.0568],\n",
       "        [0.8457, 0.0301, 0.0290, 0.0580],\n",
       "        [0.8453, 0.0301, 0.0281, 0.0580],\n",
       "        [0.8457, 0.0301, 0.0273, 0.0580],\n",
       "        [0.8457, 0.0301, 0.0273, 0.0580],\n",
       "        [0.8461, 0.0301, 0.0264, 0.0580],\n",
       "        [0.8465, 0.0307, 0.0256, 0.0591],\n",
       "        [0.8465, 0.0307, 0.0256, 0.0591],\n",
       "        [0.8470, 0.0307, 0.0247, 0.0591],\n",
       "        [0.8470, 0.0307, 0.0247, 0.0591],\n",
       "        [0.8474, 0.0307, 0.0239, 0.0591],\n",
       "        [0.8478, 0.0312, 0.0230, 0.0602],\n",
       "        [0.8478, 0.0307, 0.0230, 0.0591]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[13, 1:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60172571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389],\n",
       "        [0.1747, 0.0491, 0.0234, 0.1389]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[13, :, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c349294a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import GTSequenceDataset\n",
    "\n",
    "# SEQ_PATH = '../../Datasets/MOT20/val/MOT20-01/'\n",
    "SEQ_PATH = '../../Datasets/MOT17/val/MOT17-05-FRCNN//'\n",
    "# SEQ_PATH = '../../Datasets/DanceTrack/val/dancetrack0018/'\n",
    "# SEQ_PATH = '../../Datasets/DanceTrack/train/dancetrack0006//'\n",
    "# SEQ_PATH = '../../Datasets/SportsMOT/val/v_0kUtTtmLaJA_c004//'\n",
    "SEQ_IN_LEN = 50\n",
    "SEQ_OUT_LEN = 2\n",
    "SEQ_TOTAL_LEN = SEQ_IN_LEN + SEQ_OUT_LEN\n",
    "BATCH_SIZE = 512\n",
    "STEPS = 4\n",
    "\n",
    "# d = GTSequenceDataset.from_sequence(SEQ_PATH, seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=0, noise_coeff=0)\n",
    "d = GTSequenceDataset.from_sequence(SEQ_PATH, seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=0.15, noise_prob=0.4)\n",
    "sources = torch.tensor(d.sources).to(DEVICE)[:BATCH_SIZE]\n",
    "# targets = torch.tensor(d.targets).to(DEVICE)[:BATCH_SIZE]\n",
    "gt_sources = torch.tensor(d.gt_sources).to(DEVICE)[:BATCH_SIZE]\n",
    "targets = torch.tensor(d.gt_targets).to(DEVICE)[:BATCH_SIZE]\n",
    "# gt_targets = torch.tensor(d.gt_targets).to(DEVICE)[:BATCH_SIZE]\n",
    "\n",
    "# o = model.inference(sources, targets, num_steps=targets.size(1) - 1)\n",
    "o = model.forward(sources, targets[:, :-1])\n",
    "\n",
    "o[:, :, 0] *= d.image_width.item()\n",
    "o[:, :, 2] *= d.image_width.item()\n",
    "o[:, :, 1] *= d.image_height.item()\n",
    "o[:, :, 3] *= d.image_height.item()\n",
    "targets[:, :, 0] *= d.image_width.item()\n",
    "targets[:, :, 2] *= d.image_width.item()\n",
    "targets[:, :, 1] *= d.image_height.item()\n",
    "targets[:, :, 3] *= d.image_height.item()\n",
    "t_ = targets[:, 1:, :4]\n",
    "sources[:, :, 0] *= d.image_width.item()\n",
    "sources[:, :, 2] *= d.image_width.item()\n",
    "sources[:, :, 1] *= d.image_height.item()\n",
    "sources[:, :, 3] *= d.image_height.item()\n",
    "o_ = o[:, :, :4]\n",
    "\n",
    "index = 9\n",
    "# t[index], o[index]\n",
    "# f = (t[index] - o[index]).abs()[:, 3].mean()\n",
    "# torch.diagonal(criterion.iou(t, o), dim1=1, dim2=2).mean()\n",
    "# criterion.iou(t_, o_).mean()\n",
    "criterion.ciou(t_, o_).mean()\n",
    "# f = (t_ - o_).abs().mean()\n",
    "# f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af5a5df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[643.0000, 416.0000,  40.0000, 122.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a1b2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[639.8837, 416.5098,  40.3046, 121.7041,   0.9208]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9dfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8833, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:, :, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3976af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [10,10,10,10],\n",
    "            [30,30,40,40],\n",
    "        ],\n",
    "        [\n",
    "            [30,30,20,20],\n",
    "            [30,30,20,20]\n",
    "        ],\n",
    "        [\n",
    "            [50,50,10,10],\n",
    "            [40,40,20,20]\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "b = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [10,10,10,10],\n",
    "            [30,30,40,40],\n",
    "        ],\n",
    "        [\n",
    "            [30,30,20,20],\n",
    "            [30,30,20,20]\n",
    "        ],\n",
    "        [\n",
    "            [50,50,10,10],\n",
    "            [40,40,20,20]\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "\n",
    "criterion.ciou(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe0caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9185],\n",
       "        [0.9173],\n",
       "        [0.9353],\n",
       "        [0.9617],\n",
       "        [0.9837],\n",
       "        [0.9441],\n",
       "        [0.9207],\n",
       "        [0.8818],\n",
       "        [0.8690],\n",
       "        [0.8990],\n",
       "        [0.8124],\n",
       "        [0.9717],\n",
       "        [0.9776],\n",
       "        [0.9802],\n",
       "        [0.9065],\n",
       "        [0.8873],\n",
       "        [0.9421],\n",
       "        [0.9235],\n",
       "        [0.9258],\n",
       "        [0.9445],\n",
       "        [0.9869],\n",
       "        [0.8960],\n",
       "        [0.9319],\n",
       "        [0.9422],\n",
       "        [0.9389],\n",
       "        [0.9459],\n",
       "        [0.9354],\n",
       "        [0.9902],\n",
       "        [0.9693],\n",
       "        [0.8957],\n",
       "        [0.9465],\n",
       "        [0.9469],\n",
       "        [0.9175],\n",
       "        [0.9542],\n",
       "        [0.9261],\n",
       "        [0.8819],\n",
       "        [0.9333],\n",
       "        [0.9219],\n",
       "        [0.8752],\n",
       "        [0.9421],\n",
       "        [0.9532],\n",
       "        [0.9610],\n",
       "        [0.9848],\n",
       "        [0.9669],\n",
       "        [0.9172],\n",
       "        [0.9139],\n",
       "        [0.9219],\n",
       "        [0.9324],\n",
       "        [0.9209],\n",
       "        [0.9316],\n",
       "        [0.9463],\n",
       "        [0.9569],\n",
       "        [0.8696],\n",
       "        [0.9285],\n",
       "        [0.9420],\n",
       "        [0.9313],\n",
       "        [0.9465],\n",
       "        [0.9101],\n",
       "        [0.9182],\n",
       "        [0.9946],\n",
       "        [0.9041],\n",
       "        [0.9709],\n",
       "        [0.9335],\n",
       "        [0.9767],\n",
       "        [0.9130],\n",
       "        [0.9601],\n",
       "        [0.9249],\n",
       "        [0.9819],\n",
       "        [0.9462],\n",
       "        [0.9590],\n",
       "        [0.9288],\n",
       "        [0.9331],\n",
       "        [0.9692],\n",
       "        [0.9517],\n",
       "        [0.9839],\n",
       "        [0.9841],\n",
       "        [0.9312],\n",
       "        [0.9220],\n",
       "        [0.9061],\n",
       "        [0.9538],\n",
       "        [0.9338],\n",
       "        [0.8976],\n",
       "        [0.8981],\n",
       "        [0.8985],\n",
       "        [0.9470],\n",
       "        [0.9333],\n",
       "        [0.8924],\n",
       "        [0.9856],\n",
       "        [0.9666],\n",
       "        [0.9827],\n",
       "        [0.9142],\n",
       "        [0.9632],\n",
       "        [0.9316],\n",
       "        [0.9037],\n",
       "        [0.9375],\n",
       "        [0.8618],\n",
       "        [0.9798],\n",
       "        [0.9351],\n",
       "        [0.9050],\n",
       "        [0.9821],\n",
       "        [0.9202],\n",
       "        [0.9341],\n",
       "        [0.9447],\n",
       "        [0.8942],\n",
       "        [0.9002],\n",
       "        [0.8850],\n",
       "        [0.9222],\n",
       "        [0.9159],\n",
       "        [0.8934],\n",
       "        [0.8612],\n",
       "        [0.9381],\n",
       "        [0.8982],\n",
       "        [0.9582],\n",
       "        [0.9121],\n",
       "        [0.9729],\n",
       "        [0.9498],\n",
       "        [0.9165],\n",
       "        [0.9427],\n",
       "        [0.9363],\n",
       "        [0.9359],\n",
       "        [0.9555],\n",
       "        [0.9288],\n",
       "        [0.9424],\n",
       "        [0.9499],\n",
       "        [0.8697],\n",
       "        [0.9114],\n",
       "        [0.8637],\n",
       "        [0.9310],\n",
       "        [0.9351],\n",
       "        [0.9629],\n",
       "        [0.9927],\n",
       "        [0.9576],\n",
       "        [0.9517],\n",
       "        [0.8200],\n",
       "        [0.9014],\n",
       "        [0.9819],\n",
       "        [0.9587],\n",
       "        [0.8746],\n",
       "        [0.9404],\n",
       "        [0.9094],\n",
       "        [0.9105],\n",
       "        [0.9302],\n",
       "        [0.9035],\n",
       "        [0.9526],\n",
       "        [0.9488],\n",
       "        [0.9272],\n",
       "        [0.9603],\n",
       "        [0.9373],\n",
       "        [0.9605],\n",
       "        [0.9655],\n",
       "        [0.9510],\n",
       "        [0.8566],\n",
       "        [0.8732],\n",
       "        [0.8919],\n",
       "        [0.9226],\n",
       "        [0.9148],\n",
       "        [0.8790],\n",
       "        [0.9547],\n",
       "        [0.9868],\n",
       "        [0.9336],\n",
       "        [0.9737],\n",
       "        [0.9708],\n",
       "        [0.8907],\n",
       "        [0.9446],\n",
       "        [0.9541],\n",
       "        [0.8856],\n",
       "        [0.8969],\n",
       "        [0.9085],\n",
       "        [0.9745],\n",
       "        [0.9680],\n",
       "        [0.8910],\n",
       "        [0.9384],\n",
       "        [0.9592],\n",
       "        [0.8689],\n",
       "        [0.9453],\n",
       "        [0.9016],\n",
       "        [0.9600],\n",
       "        [0.9587],\n",
       "        [0.9247],\n",
       "        [0.9696],\n",
       "        [0.9645],\n",
       "        [0.9058],\n",
       "        [0.9653],\n",
       "        [0.9295],\n",
       "        [0.9425],\n",
       "        [0.8642],\n",
       "        [0.9021],\n",
       "        [0.9628],\n",
       "        [0.9348],\n",
       "        [0.9676],\n",
       "        [0.9028],\n",
       "        [0.9181],\n",
       "        [0.9547],\n",
       "        [0.9751],\n",
       "        [0.9616],\n",
       "        [0.8734],\n",
       "        [0.8423],\n",
       "        [0.9666],\n",
       "        [0.8912],\n",
       "        [0.8927],\n",
       "        [0.8403],\n",
       "        [0.9898],\n",
       "        [0.9295],\n",
       "        [0.8722],\n",
       "        [0.9203],\n",
       "        [0.8759],\n",
       "        [0.9336],\n",
       "        [0.9331],\n",
       "        [0.9628],\n",
       "        [0.8943],\n",
       "        [0.9505],\n",
       "        [0.8672],\n",
       "        [0.9460],\n",
       "        [0.9105],\n",
       "        [0.9452],\n",
       "        [0.8778],\n",
       "        [0.8967],\n",
       "        [0.9136],\n",
       "        [0.9410],\n",
       "        [0.8337],\n",
       "        [0.9339],\n",
       "        [0.9270],\n",
       "        [0.9113],\n",
       "        [0.9212],\n",
       "        [0.9095],\n",
       "        [0.9021],\n",
       "        [0.8818],\n",
       "        [0.8878],\n",
       "        [0.9118],\n",
       "        [0.9143],\n",
       "        [0.9130],\n",
       "        [0.9056],\n",
       "        [0.9429],\n",
       "        [0.9395],\n",
       "        [0.9488],\n",
       "        [0.9275],\n",
       "        [0.9324],\n",
       "        [0.9647],\n",
       "        [0.9142],\n",
       "        [0.9017],\n",
       "        [0.8880],\n",
       "        [0.8835],\n",
       "        [0.9368],\n",
       "        [0.9559],\n",
       "        [0.9795],\n",
       "        [0.9923],\n",
       "        [0.9777],\n",
       "        [0.9592],\n",
       "        [0.8995],\n",
       "        [0.9161],\n",
       "        [0.9877],\n",
       "        [0.8671],\n",
       "        [0.8771],\n",
       "        [0.9441],\n",
       "        [0.9147],\n",
       "        [0.8866],\n",
       "        [0.9134],\n",
       "        [0.9526],\n",
       "        [0.9149],\n",
       "        [0.8523],\n",
       "        [0.9364],\n",
       "        [0.8894],\n",
       "        [0.9342],\n",
       "        [0.9364],\n",
       "        [0.9849],\n",
       "        [0.9925],\n",
       "        [0.9788],\n",
       "        [0.9464],\n",
       "        [0.9071],\n",
       "        [0.9063],\n",
       "        [0.8747],\n",
       "        [0.8520],\n",
       "        [0.9141],\n",
       "        [0.9381],\n",
       "        [0.9638],\n",
       "        [0.9733],\n",
       "        [0.9876],\n",
       "        [0.9281],\n",
       "        [0.8969],\n",
       "        [0.9710],\n",
       "        [0.9051],\n",
       "        [0.9283],\n",
       "        [0.9792],\n",
       "        [0.9397],\n",
       "        [0.9544],\n",
       "        [0.8864],\n",
       "        [0.8865],\n",
       "        [0.9703],\n",
       "        [0.9489],\n",
       "        [0.9636],\n",
       "        [0.9256],\n",
       "        [0.9321],\n",
       "        [0.9884],\n",
       "        [0.9655],\n",
       "        [0.8952],\n",
       "        [0.9894],\n",
       "        [0.9228],\n",
       "        [0.9819],\n",
       "        [0.8720],\n",
       "        [0.9545],\n",
       "        [0.9134],\n",
       "        [0.8914],\n",
       "        [0.9426],\n",
       "        [0.9321],\n",
       "        [0.9656],\n",
       "        [0.9224],\n",
       "        [0.9393],\n",
       "        [0.9151],\n",
       "        [0.9831],\n",
       "        [0.9731],\n",
       "        [0.9079],\n",
       "        [0.9038],\n",
       "        [0.8977],\n",
       "        [0.9783],\n",
       "        [0.9015],\n",
       "        [0.9371],\n",
       "        [0.9245],\n",
       "        [0.8551],\n",
       "        [0.9023],\n",
       "        [0.8799],\n",
       "        [0.9810],\n",
       "        [0.9434],\n",
       "        [0.9426],\n",
       "        [0.9482],\n",
       "        [0.8952],\n",
       "        [0.9784],\n",
       "        [0.9519],\n",
       "        [0.8985],\n",
       "        [0.9387],\n",
       "        [0.8761],\n",
       "        [0.9489],\n",
       "        [0.9542],\n",
       "        [0.9002],\n",
       "        [0.9578],\n",
       "        [0.9020],\n",
       "        [0.8831],\n",
       "        [0.9361],\n",
       "        [0.8976],\n",
       "        [0.8837],\n",
       "        [0.8657],\n",
       "        [0.9005],\n",
       "        [0.9765],\n",
       "        [0.8969],\n",
       "        [0.9275],\n",
       "        [0.9218],\n",
       "        [0.9069],\n",
       "        [0.9168],\n",
       "        [0.8914],\n",
       "        [0.9049],\n",
       "        [0.9615],\n",
       "        [0.9085],\n",
       "        [0.9626],\n",
       "        [0.9726],\n",
       "        [0.9358],\n",
       "        [0.9459],\n",
       "        [0.9505],\n",
       "        [0.9433],\n",
       "        [0.9438],\n",
       "        [0.9643],\n",
       "        [0.9473],\n",
       "        [0.9139],\n",
       "        [0.8981],\n",
       "        [0.8851],\n",
       "        [0.8891],\n",
       "        [0.9612],\n",
       "        [0.9885],\n",
       "        [0.9139],\n",
       "        [0.9306],\n",
       "        [0.9111],\n",
       "        [0.9198],\n",
       "        [0.9672],\n",
       "        [0.9291],\n",
       "        [0.9818],\n",
       "        [0.9300],\n",
       "        [0.8991],\n",
       "        [0.9395],\n",
       "        [0.9481],\n",
       "        [0.9413],\n",
       "        [0.9913],\n",
       "        [0.9904],\n",
       "        [0.8035],\n",
       "        [0.8952],\n",
       "        [0.9231],\n",
       "        [0.9770],\n",
       "        [0.9742],\n",
       "        [0.9135],\n",
       "        [0.9743],\n",
       "        [0.9684],\n",
       "        [0.9606],\n",
       "        [0.8980],\n",
       "        [0.9146],\n",
       "        [0.9261],\n",
       "        [0.9145],\n",
       "        [0.9306],\n",
       "        [0.9655],\n",
       "        [0.9124],\n",
       "        [0.9288],\n",
       "        [0.9513],\n",
       "        [0.8909],\n",
       "        [0.9680],\n",
       "        [0.9391],\n",
       "        [0.9203],\n",
       "        [0.8826],\n",
       "        [0.9056],\n",
       "        [0.9237],\n",
       "        [0.9054],\n",
       "        [0.8986],\n",
       "        [0.9270],\n",
       "        [0.8953],\n",
       "        [0.9517],\n",
       "        [0.9269],\n",
       "        [0.9109],\n",
       "        [0.9349],\n",
       "        [0.9475],\n",
       "        [0.9462],\n",
       "        [0.8790],\n",
       "        [0.8983],\n",
       "        [0.8859],\n",
       "        [0.8759],\n",
       "        [0.9322],\n",
       "        [0.9600],\n",
       "        [0.8465],\n",
       "        [0.9289],\n",
       "        [0.9314],\n",
       "        [0.9476],\n",
       "        [0.8954],\n",
       "        [0.9217],\n",
       "        [0.9546],\n",
       "        [0.8808],\n",
       "        [0.9548],\n",
       "        [0.9243],\n",
       "        [0.9058],\n",
       "        [0.9177],\n",
       "        [0.9231],\n",
       "        [0.9463],\n",
       "        [0.9264],\n",
       "        [0.9032],\n",
       "        [0.8841],\n",
       "        [0.8725],\n",
       "        [0.9338],\n",
       "        [0.9827],\n",
       "        [0.9054],\n",
       "        [0.9467],\n",
       "        [0.9706],\n",
       "        [0.9499],\n",
       "        [0.9864],\n",
       "        [0.9331],\n",
       "        [0.9284],\n",
       "        [0.9302],\n",
       "        [0.8975],\n",
       "        [0.9495],\n",
       "        [0.9072],\n",
       "        [0.9827],\n",
       "        [0.9725],\n",
       "        [0.9208],\n",
       "        [0.8457],\n",
       "        [0.8858],\n",
       "        [0.9574],\n",
       "        [0.9458],\n",
       "        [0.8904],\n",
       "        [0.8550],\n",
       "        [0.8863],\n",
       "        [0.9076],\n",
       "        [0.9816],\n",
       "        [0.8780],\n",
       "        [0.9360],\n",
       "        [0.9263],\n",
       "        [0.9054],\n",
       "        [0.9062],\n",
       "        [0.9153],\n",
       "        [0.9661],\n",
       "        [0.8990],\n",
       "        [0.9881],\n",
       "        [0.9640],\n",
       "        [0.8989],\n",
       "        [0.9370],\n",
       "        [0.9442],\n",
       "        [0.9829],\n",
       "        [0.9255],\n",
       "        [0.9155],\n",
       "        [0.9340],\n",
       "        [0.8616],\n",
       "        [0.9061],\n",
       "        [0.8912],\n",
       "        [0.9798],\n",
       "        [0.9867],\n",
       "        [0.9624],\n",
       "        [0.8850],\n",
       "        [0.8467],\n",
       "        [0.9435],\n",
       "        [0.9317],\n",
       "        [0.9317],\n",
       "        [0.9600],\n",
       "        [0.9471],\n",
       "        [0.8986],\n",
       "        [0.9137],\n",
       "        [0.9175],\n",
       "        [0.8949],\n",
       "        [0.9736],\n",
       "        [0.8855],\n",
       "        [0.9689],\n",
       "        [0.8653],\n",
       "        [0.8497],\n",
       "        [0.9574],\n",
       "        [0.9044],\n",
       "        [0.9066],\n",
       "        [0.9603],\n",
       "        [0.9669],\n",
       "        [0.9130],\n",
       "        [0.8861],\n",
       "        [0.8121],\n",
       "        [0.9347]], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:, :, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a73f55b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0039,  0.0035],\n",
       "        [ 0.0043,  0.0031],\n",
       "        [ 0.0070,  0.0016],\n",
       "        ...,\n",
       "        [-0.0070, -0.0188],\n",
       "        [ 0.0148, -0.0070],\n",
       "        [-0.0023, -0.0047]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdba22e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4023, 0.4671, 0.0672, 0.2343, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_sources[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
