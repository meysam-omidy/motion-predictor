{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa632af",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b47ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1276594, Val samples: 666289\n"
     ]
    }
   ],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "SEQ_IN_LEN = 30\n",
    "SEQ_OUT_LEN = 2\n",
    "SEQ_TOTAL_LEN = 32\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "BASE_DIR = '../../Datasets/'\n",
    "train_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}DanceTrack/train',\n",
    "    f'{BASE_DIR}MOT17/train',\n",
    "    f'{BASE_DIR}MOT20/train'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=0.5, noise_coeff=0.5)\n",
    "\n",
    "val_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}DanceTrack/val',\n",
    "    f'{BASE_DIR}MOT17/val',\n",
    "    f'{BASE_DIR}MOT20/val'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=0.5, noise_coeff=0.5)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ffe87",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c4937d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/.local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lstm import LSTMPredictor\n",
    "from loss import LossFunction\n",
    "from torch import optim\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "model = LSTMPredictor(middle_dim=64, hidden_dim=256, num_layers=1).to(DEVICE)\n",
    "criterion = LossFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6b52806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.101490776536144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7f21f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15\n",
      "Epoch 1: Train Loss = 0.06414034, Val Loss = 0.08256277, LR = 0.00199818\n",
      "Epoch 2: Train Loss = 0.04562454, Val Loss = 0.07837529, LR = 0.00199271\n",
      "Epoch 3: Train Loss = 0.04282197, Val Loss = 0.07818616, LR = 0.00198362\n",
      "Epoch 4: Train Loss = 0.04172837, Val Loss = 0.08411249, LR = 0.00197094\n",
      "Epoch 5: Train Loss = 0.04091067, Val Loss = 0.07815535, LR = 0.00195472\n",
      "Epoch 6: Train Loss = 0.04044936, Val Loss = 0.07928688, LR = 0.00193502\n",
      "Epoch 7: Train Loss = 0.03999297, Val Loss = 0.07996182, LR = 0.00191190\n",
      "Epoch 8: Train Loss = 0.03972748, Val Loss = 0.08286103, LR = 0.00188546\n",
      "Epoch 9: Train Loss = 0.03924480, Val Loss = 0.08378812, LR = 0.00185578\n",
      "Epoch 10: Train Loss = 0.03896793, Val Loss = 0.08029294, LR = 0.00182298\n",
      "Epoch 11: Train Loss = 0.03881455, Val Loss = 0.08028612, LR = 0.00178718\n",
      "Epoch 12: Train Loss = 0.03849943, Val Loss = 0.07681794, LR = 0.00174851\n",
      "Epoch 13: Train Loss = 0.03817027, Val Loss = 0.08059067, LR = 0.00170711\n",
      "Epoch 14: Train Loss = 0.03800686, Val Loss = 0.07935416, LR = 0.00166312\n",
      "Epoch 15: Train Loss = 0.03761068, Val Loss = 0.07931878, LR = 0.00161672\n",
      "Training complete. Best Val Loss: 0.076817938052964\n",
      "0.2 10\n",
      "Epoch 1: Train Loss = 0.05125807, Val Loss = 0.07889682, LR = 0.00156806\n",
      "Epoch 2: Train Loss = 0.05241428, Val Loss = 0.07287941, LR = 0.00151734\n",
      "Epoch 3: Train Loss = 0.05035186, Val Loss = 0.08002680, LR = 0.00146472\n",
      "Epoch 4: Train Loss = 0.04980025, Val Loss = 0.07391039, LR = 0.00141041\n",
      "Epoch 5: Train Loss = 0.04949072, Val Loss = 0.07346756, LR = 0.00135460\n",
      "Epoch 6: Train Loss = 0.04926910, Val Loss = 0.07395351, LR = 0.00129750\n",
      "Epoch 7: Train Loss = 0.04902387, Val Loss = 0.07778643, LR = 0.00123932\n",
      "Epoch 8: Train Loss = 0.04859496, Val Loss = 0.07302370, LR = 0.00118026\n",
      "Epoch 9: Train Loss = 0.04849019, Val Loss = 0.07294202, LR = 0.00112054\n",
      "Epoch 10: Train Loss = 0.04818676, Val Loss = 0.07109119, LR = 0.00106038\n",
      "Training complete. Best Val Loss: 0.07109119018259012\n",
      "0.4 10\n",
      "Epoch 1: Train Loss = 0.06051179, Val Loss = 0.07413969, LR = 0.00100000\n",
      "Epoch 2: Train Loss = 0.06008640, Val Loss = 0.07278172, LR = 0.00093962\n",
      "Epoch 3: Train Loss = 0.05969670, Val Loss = 0.07126310, LR = 0.00087946\n",
      "Epoch 4: Train Loss = 0.05927260, Val Loss = 0.07133586, LR = 0.00081974\n",
      "Epoch 5: Train Loss = 0.05890727, Val Loss = 0.06890671, LR = 0.00076068\n",
      "Epoch 6: Train Loss = 0.05851390, Val Loss = 0.07067558, LR = 0.00070250\n",
      "Epoch 7: Train Loss = 0.05816720, Val Loss = 0.06977188, LR = 0.00064540\n",
      "Epoch 8: Train Loss = 0.05790173, Val Loss = 0.07146020, LR = 0.00058959\n",
      "Epoch 9: Train Loss = 0.05759260, Val Loss = 0.07029019, LR = 0.00053528\n",
      "Epoch 10: Train Loss = 0.05732203, Val Loss = 0.06877929, LR = 0.00048266\n",
      "Training complete. Best Val Loss: 0.06877929384935014\n",
      "0.6 10\n",
      "Epoch 1: Train Loss = 0.06936588, Val Loss = 0.06782569, LR = 0.00043194\n",
      "Epoch 2: Train Loss = 0.06902790, Val Loss = 0.06825645, LR = 0.00038328\n",
      "Epoch 3: Train Loss = 0.06875737, Val Loss = 0.06920293, LR = 0.00033688\n",
      "Epoch 4: Train Loss = 0.06852060, Val Loss = 0.06895752, LR = 0.00029289\n",
      "Epoch 5: Train Loss = 0.06832052, Val Loss = 0.06848471, LR = 0.00025149\n",
      "Epoch 6: Train Loss = 0.06808639, Val Loss = 0.06839127, LR = 0.00021282\n",
      "Epoch 7: Train Loss = 0.06790635, Val Loss = 0.06876169, LR = 0.00017702\n",
      "Epoch 8: Train Loss = 0.06774227, Val Loss = 0.06913590, LR = 0.00014422\n",
      "Epoch 9: Train Loss = 0.06758405, Val Loss = 0.06911750, LR = 0.00011454\n",
      "Epoch 10: Train Loss = 0.06743889, Val Loss = 0.06917790, LR = 0.00008810\n",
      "Training complete. Best Val Loss: 0.06782569458479049\n",
      "0.8 5\n",
      "Epoch 1: Train Loss = 0.07963354, Val Loss = 0.06925642, LR = 0.00006498\n",
      "Epoch 2: Train Loss = 0.07945852, Val Loss = 0.06928422, LR = 0.00004528\n",
      "Epoch 3: Train Loss = 0.07934374, Val Loss = 0.06915219, LR = 0.00002906\n",
      "Epoch 4: Train Loss = 0.07925711, Val Loss = 0.06917386, LR = 0.00001638\n",
      "Epoch 5: Train Loss = 0.07918867, Val Loss = 0.06916175, LR = 0.00000729\n",
      "Training complete. Best Val Loss: 0.06782569458479049\n"
     ]
    }
   ],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=42)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "NUM_EPOCHS = [15, 10, 10, 10, 5]\n",
    "PS = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=sum(NUM_EPOCHS) + 2)\n",
    "\n",
    "\n",
    "# for p, lr, num_epochs in [[0.2, 1e-3, 10], [0.4, 5e-4, 10], [0.6, 5e-4, 10]]:\n",
    "for p, num_epochs in zip(PS, NUM_EPOCHS):\n",
    "\n",
    "    print(p, num_epochs)\n",
    "\n",
    "    SEQ_IN_LEN = 30\n",
    "    SEQ_OUT_LEN = 2\n",
    "    SEQ_TOTAL_LEN = 32\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    BASE_DIR = '../../Datasets/'\n",
    "    train_dataset = GTSequenceDataset.from_roots([\n",
    "        f'{BASE_DIR}DanceTrack/train',\n",
    "        f'{BASE_DIR}MOT17/train',\n",
    "        f'{BASE_DIR}MOT20/train'\n",
    "    ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=p, noise_coeff=2)\n",
    "\n",
    "    val_dataset = GTSequenceDataset.from_roots([\n",
    "        f'{BASE_DIR}DanceTrack/val',\n",
    "        f'{BASE_DIR}MOT17/val',\n",
    "        f'{BASE_DIR}MOT20/val'\n",
    "    ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=0.6, noise_coeff=2)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # LR = 2e-3\n",
    "    # NUM_EPOCHS = [10, 5, 5, 5, 5, 5][0:1]\n",
    "    # LRS = [5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4][0:1]\n",
    "    # TEACHER_FORCING_RATIOS = [1, 0.8, 0.6, 0.4, 0.2, 0][0:1]\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # for num_epochs, lr, teacher_forcing_ratio in zip(NUM_EPOCHS, LRS, TEACHER_FORCING_RATIOS):\n",
    "\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = model.train_one_epoch(train_loader, optimizer, criterion, 1)\n",
    "        val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weight('pretrained/lstm-base-m64-h256-wn-v2.pth')\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "\n",
    "    print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b560b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0460dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20  Lr: 0.0005  Teacher Forcing Ratio: 1\n",
      "Epoch 1: Train Loss = 0.06342130, Val Loss = 0.05451159, LR = 0.00198883\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Teacher Forcing Ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteacher_forcing_ratio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_loader, criterion)\n\u001b[1;32m     19\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Desktop/Projects/motion-predictor/lstm.py:69\u001b[0m, in \u001b[0;36mLSTMPredictor.train_one_epoch\u001b[0;34m(self, dataloader, optimizer, criterion, teacher_forcing_ratio, device)\u001b[0m\n\u001b[1;32m     66\u001b[0m trg \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, trg[:, \u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     72\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/Projects/motion-predictor/lstm.py:22\u001b[0m, in \u001b[0;36mLSTMPredictor.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     20\u001b[0m batch_size, trg_size, _ \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Encode\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m _, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# First input to decoder is the last frame of src\u001b[39;00m\n\u001b[1;32m     25\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m trg[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# shape (batch, 1, 4)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1137\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1145\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR = 2e-3\n",
    "NUM_EPOCHS = [20, 5, 5, 5, 5, 5][0:1]\n",
    "LRS = [5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4][0:1]\n",
    "TEACHER_FORCING_RATIOS = [1, 0.8, 0.6, 0.4, 0.2, 0][0:1]\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=sum(NUM_EPOCHS) + 1)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for num_epochs, lr, teacher_forcing_ratio in zip(NUM_EPOCHS, LRS, TEACHER_FORCING_RATIOS):\n",
    "\n",
    "    print(f'Epochs: {num_epochs}  Lr: {lr}  Teacher Forcing Ratio: {teacher_forcing_ratio}')\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = model.train_one_epoch(train_loader, optimizer, criterion, teacher_forcing_ratio)\n",
    "        val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weight('pretrained/lstm-base-m64-h256-l1.pth')\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "\n",
    "    print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44cb98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weight('pretrained/lstm-base-m64-h256-wn-v2.pth')\n",
    "model.load_weight('pretrained/lstm-base-m64-h256-wn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6344962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weight('pretrained/lstm-base-m64-h256-l1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67bf7b",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd58e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import GTSequenceDataset\n",
    "\n",
    "SEQ_PATH = '../../Datasets/MOT20/val/MOT20-01/'\n",
    "# SEQ_PATH = '../../Datasets/MOT17/val/MOT17-04-FRCNN/'\n",
    "# SEQ_PATH = '../../Datasets/DanceTrack/val/dancetrack0004/'\n",
    "SEQ_IN_LEN = 30\n",
    "SEQ_OUT_LEN = 2\n",
    "SEQ_TOTAL_LEN = 32\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "d = GTSequenceDataset.from_sequence(SEQ_PATH, seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN)\n",
    "# d = GTSequenceDataset.from_sequence(SEQ_PATH, seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=0.6, noise_coeff=2)\n",
    "sources = torch.tensor(d.sources).to(DEVICE)[:BATCH_SIZE]\n",
    "targets = torch.tensor(d.targets).to(DEVICE)[:BATCH_SIZE]\n",
    "\n",
    "o = model.inference(sources, targets, num_steps=targets.size(1) - 1)\n",
    "\n",
    "o[:, :, 0] *= d.image_width.item()\n",
    "o[:, :, 2] *= d.image_width.item()\n",
    "o[:, :, 1] *= d.image_height.item()\n",
    "o[:, :, 3] *= d.image_height.item()\n",
    "targets[:, :, 0] *= d.image_width.item()\n",
    "targets[:, :, 2] *= d.image_width.item()\n",
    "targets[:, :, 1] *= d.image_height.item()\n",
    "targets[:, :, 3] *= d.image_height.item()\n",
    "t = targets[:, 1:]\n",
    "sources[:, :, 0] *= d.image_width.item()\n",
    "sources[:, :, 2] *= d.image_width.item()\n",
    "sources[:, :, 1] *= d.image_height.item()\n",
    "sources[:, :, 3] *= d.image_height.item()\n",
    "\n",
    "index = 9\n",
    "# t[index], o[index]\n",
    "# f = (t[index] - o[index]).abs()[:, 3].mean()\n",
    "f = (t - o).abs().mean()\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "685bf336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 294.3531,  811.7768,  413.6157, 1081.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c2c4581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 286.7705,  810.1767,  418.4162, 1081.0775]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75548378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.image_height.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e1c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4595, 0.3603, 0.5068, 0.6890],\n",
       "         [0.4916, 0.3975, 0.5206, 0.7048]],\n",
       "\n",
       "        [[0.4916, 0.3975, 0.5206, 0.7048],\n",
       "         [0.4530, 0.4065, 0.5024, 0.6868]],\n",
       "\n",
       "        [[0.4530, 0.4065, 0.5024, 0.6868],\n",
       "         [0.4324, 0.4058, 0.5474, 0.7003]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2288, 0.5286, 0.3329, 0.7175],\n",
       "         [0.2476, 0.5468, 0.3747, 0.6862]],\n",
       "\n",
       "        [[0.2476, 0.5468, 0.3747, 0.6862],\n",
       "         [0.2156, 0.5008, 0.3438, 0.7099]],\n",
       "\n",
       "        [[0.2156, 0.5008, 0.3438, 0.7099],\n",
       "         [0.2274, 0.5202, 0.3164, 0.7094]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
