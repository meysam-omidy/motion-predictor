{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa632af",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b47ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "SEQ_IN_LEN = 30\n",
    "SEQ_OUT_LEN = 2\n",
    "SEQ_TOTAL_LEN = 32\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "BASE_DIR = '../../.Datasets/'\n",
    "train_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}DanceTrack/train',\n",
    "    f'{BASE_DIR}MOT17/train',\n",
    "    f'{BASE_DIR}MOT20/train'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN)\n",
    "\n",
    "val_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}DanceTrack/GTSequenceDataset',\n",
    "    f'{BASE_DIR}MOT17/val',\n",
    "    f'{BASE_DIR}MOT20/val'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ffe87",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4937d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm import ImprovedLSTMPredictor\n",
    "from loss import LossFunction\n",
    "from torch import optim\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "model = ImprovedLSTMPredictor(middle_dim=64, hidden_dim=256, num_layers=1).to(DEVICE)\n",
    "criterion = LossFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b560b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-3\n",
    "NUM_EPOCHS = [20, 5, 5, 5, 5, 5][0:1]\n",
    "LRS = [5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4][0:1]\n",
    "TEACHER_FORCING_RATIOS = [1, 0.8, 0.6, 0.4, 0.2, 0][0:1]\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=sum(NUM_EPOCHS) + 1)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for num_epochs, lr, teacher_forcing_ratio in zip(NUM_EPOCHS, LRS, TEACHER_FORCING_RATIOS):\n",
    "\n",
    "    print(f'Epochs: {num_epochs}  Lr: {lr}  Teacher Forcing Ratio: {teacher_forcing_ratio}')\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = model.train_one_epoch(train_loader, optimizer, criterion, teacher_forcing_ratio)\n",
    "        val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weight('pretrained/')\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "\n",
    "    print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67bf7b",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd58e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(210.2011, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import GTSequenceDataset\n",
    "\n",
    "SEQ_PATH = '../../.Datasets/DanceTrack/val/dancetrack0004/'\n",
    "SEQ_IN_LEN = 30\n",
    "SEQ_OUT_LEN = 2\n",
    "SEQ_TOTAL_LEN = 32\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "d = GTSequenceDataset.from_sequence(SEQ_PATH, seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise=True)\n",
    "sources = torch.tensor(d.sources).to(DEVICE)[:BATCH_SIZE]\n",
    "targets = torch.tensor(d.targets).to(DEVICE)[:BATCH_SIZE]\n",
    "\n",
    "o = model.inference(sources, targets, num_steps=targets.size(1) - 1)\n",
    "\n",
    "o[:, :, 0] *= d.image_width.item()\n",
    "o[:, :, 2] *= d.image_width.item()\n",
    "o[:, :, 1] *= d.image_height.item()\n",
    "o[:, :, 3] *= d.image_height.item()\n",
    "targets[:, :, 0] *= d.image_width.item()\n",
    "targets[:, :, 2] *= d.image_width.item()\n",
    "targets[:, :, 1] *= d.image_height.item()\n",
    "targets[:, :, 3] *= d.image_height.item()\n",
    "t = targets[:, 1:]\n",
    "sources[:, :, 0] *= d.image_width.item()\n",
    "sources[:, :, 2] *= d.image_width.item()\n",
    "sources[:, :, 1] *= d.image_height.item()\n",
    "sources[:, :, 3] *= d.image_height.item()\n",
    "\n",
    "index = 9\n",
    "# t[index], o[index]\n",
    "# f = (t[index] - o[index]).abs()[:, 3].mean()\n",
    "f = (t - o).abs().mean()\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75548378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.image_height.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e1c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4595, 0.3603, 0.5068, 0.6890],\n",
       "         [0.4916, 0.3975, 0.5206, 0.7048]],\n",
       "\n",
       "        [[0.4916, 0.3975, 0.5206, 0.7048],\n",
       "         [0.4530, 0.4065, 0.5024, 0.6868]],\n",
       "\n",
       "        [[0.4530, 0.4065, 0.5024, 0.6868],\n",
       "         [0.4324, 0.4058, 0.5474, 0.7003]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2288, 0.5286, 0.3329, 0.7175],\n",
       "         [0.2476, 0.5468, 0.3747, 0.6862]],\n",
       "\n",
       "        [[0.2476, 0.5468, 0.3747, 0.6862],\n",
       "         [0.2156, 0.5008, 0.3438, 0.7099]],\n",
       "\n",
       "        [[0.2156, 0.5008, 0.3438, 0.7099],\n",
       "         [0.2274, 0.5202, 0.3164, 0.7094]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
