{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa632af",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b47ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1313429, Val samples: 689264\n"
     ]
    }
   ],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "SEQ_IN_LEN = 10\n",
    "SEQ_OUT_LEN = 10\n",
    "SEQ_TOTAL_LEN = 20\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "BASE_DIR = '../../Datasets/'\n",
    "train_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}DanceTrack/train',\n",
    "    f'{BASE_DIR}MOT17/train',\n",
    "    f'{BASE_DIR}MOT20/train'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN)\n",
    "\n",
    "val_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}DanceTrack/val',\n",
    "    f'{BASE_DIR}MOT17/val',\n",
    "    f'{BASE_DIR}MOT20/val'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ffe87",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4937d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_decoder import LSTMPredictor\n",
    "from loss import LossFunction\n",
    "from torch import optim\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "# model = MotionTransformer(num_enc_layers=1, num_dec_layers=1, dim_ff=64, d_model=32, dropout=0, nhead=4).to(DEVICE)\n",
    "# model = ImprovedLSTMPredictor(middle_dim=128, hidden_dim=512, num_layers=1).to(DEVICE)\n",
    "model = LSTMPredictor(middle_dim=128, hidden_dim=512, num_layers=1).to(DEVICE)\n",
    "criterion = LossFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6b52806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06770345217165835"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f21f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15\n",
      "Epoch 1: Train Loss = 0.00001353, Val Loss = 0.00001081, LR = 0.00199818\n",
      "Epoch 2: Train Loss = 0.00000664, Val Loss = 0.00001072, LR = 0.00199271\n",
      "Epoch 3: Train Loss = 0.00000608, Val Loss = 0.00001097, LR = 0.00198362\n",
      "Epoch 4: Train Loss = 0.00000587, Val Loss = 0.00001106, LR = 0.00197094\n",
      "Epoch 5: Train Loss = 0.00000573, Val Loss = 0.00001093, LR = 0.00195472\n",
      "Epoch 6: Train Loss = 0.00000562, Val Loss = 0.00001103, LR = 0.00193502\n",
      "Epoch 7: Train Loss = 0.00000553, Val Loss = 0.00001065, LR = 0.00191190\n",
      "Epoch 8: Train Loss = 0.00000544, Val Loss = 0.00001123, LR = 0.00188546\n",
      "Epoch 9: Train Loss = 0.00000539, Val Loss = 0.00001103, LR = 0.00185578\n",
      "Epoch 10: Train Loss = 0.00000533, Val Loss = 0.00001081, LR = 0.00182298\n",
      "Epoch 11: Train Loss = 0.00000527, Val Loss = 0.00001084, LR = 0.00178718\n",
      "Epoch 12: Train Loss = 0.00000522, Val Loss = 0.00001070, LR = 0.00174851\n",
      "Epoch 13: Train Loss = 0.00000517, Val Loss = 0.00001056, LR = 0.00170711\n",
      "Epoch 14: Train Loss = 0.00000513, Val Loss = 0.00001087, LR = 0.00166312\n",
      "Epoch 15: Train Loss = 0.00000508, Val Loss = 0.00001103, LR = 0.00161672\n",
      "Training complete. Best Val Loss: 1.0560675105841134e-05\n",
      "0.2 10\n",
      "Epoch 1: Train Loss = 0.00000712, Val Loss = 0.00001017, LR = 0.00156806\n",
      "Epoch 2: Train Loss = 0.00000702, Val Loss = 0.00001013, LR = 0.00151734\n",
      "Epoch 3: Train Loss = 0.00000694, Val Loss = 0.00001019, LR = 0.00146472\n",
      "Epoch 4: Train Loss = 0.00000688, Val Loss = 0.00001008, LR = 0.00141041\n",
      "Epoch 5: Train Loss = 0.00000679, Val Loss = 0.00000997, LR = 0.00135460\n",
      "Epoch 6: Train Loss = 0.00000670, Val Loss = 0.00001001, LR = 0.00129750\n",
      "Epoch 7: Train Loss = 0.00000662, Val Loss = 0.00000986, LR = 0.00123932\n",
      "Epoch 8: Train Loss = 0.00000650, Val Loss = 0.00000987, LR = 0.00118026\n",
      "Epoch 9: Train Loss = 0.00000642, Val Loss = 0.00000988, LR = 0.00112054\n",
      "Epoch 10: Train Loss = 0.00000631, Val Loss = 0.00000981, LR = 0.00106038\n",
      "Training complete. Best Val Loss: 9.814378019582475e-06\n",
      "0.4 10\n",
      "Epoch 1: Train Loss = 0.00000811, Val Loss = 0.00000959, LR = 0.00100000\n",
      "Epoch 2: Train Loss = 0.00000790, Val Loss = 0.00000951, LR = 0.00093962\n",
      "Epoch 3: Train Loss = 0.00000773, Val Loss = 0.00000954, LR = 0.00087946\n",
      "Epoch 4: Train Loss = 0.00000758, Val Loss = 0.00000950, LR = 0.00081974\n",
      "Epoch 5: Train Loss = 0.00000742, Val Loss = 0.00000961, LR = 0.00076068\n",
      "Epoch 6: Train Loss = 0.00000725, Val Loss = 0.00000966, LR = 0.00070250\n",
      "Epoch 7: Train Loss = 0.00000708, Val Loss = 0.00000962, LR = 0.00064540\n",
      "Epoch 8: Train Loss = 0.00000692, Val Loss = 0.00000990, LR = 0.00058959\n",
      "Epoch 9: Train Loss = 0.00000672, Val Loss = 0.00001018, LR = 0.00053528\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     54\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_one_epoch(train_loader, optimizer, criterion, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n",
      "File \u001b[0;32m~/Desktop/Projects/motion-predictor/lstm_improved.py:118\u001b[0m, in \u001b[0;36mImprovedLSTMPredictor.evaluate\u001b[0;34m(self, dataloader, criterion, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(src, trg, num_steps\u001b[38;5;241m=\u001b[39mtrg\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    117\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output, trg[:, \u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m--> 118\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=42)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "NUM_EPOCHS = [15, 10, 10, 10, 5]\n",
    "PS = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-3)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=sum(NUM_EPOCHS) + 2)\n",
    "\n",
    "\n",
    "# for p, lr, num_epochs in [[0.2, 1e-3, 10], [0.4, 5e-4, 10], [0.6, 5e-4, 10]]:\n",
    "for p, num_epochs in zip(PS, NUM_EPOCHS):\n",
    "\n",
    "    \n",
    "\n",
    "    SEQ_IN_LEN = 30\n",
    "    SEQ_OUT_LEN = 2\n",
    "    SEQ_TOTAL_LEN = 32\n",
    "    BATCH_SIZE = 512\n",
    "\n",
    "    BASE_DIR = '../../Datasets/'\n",
    "    train_dataset = GTSequenceDataset.from_roots([\n",
    "        f'{BASE_DIR}DanceTrack/train',\n",
    "        f'{BASE_DIR}MOT17/train',\n",
    "        f'{BASE_DIR}MOT20/train'\n",
    "    ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=p, noise_coeff=2)\n",
    "\n",
    "    val_dataset = GTSequenceDataset.from_roots([\n",
    "        f'{BASE_DIR}DanceTrack/val',\n",
    "        f'{BASE_DIR}MOT17/val',\n",
    "        f'{BASE_DIR}MOT20/val'\n",
    "    ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=0.6, noise_coeff=2)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # LR = 2e-3\n",
    "    # NUM_EPOCHS = [10, 5, 5, 5, 5, 5][0:1]\n",
    "    # LRS = [5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4][0:1]\n",
    "    # TEACHER_FORCING_RATIOS = [1, 0.8, 0.6, 0.4, 0.2, 0][0:1]\n",
    "\n",
    "    print(p, num_epochs)\n",
    "\n",
    "    \n",
    "\n",
    "    # for num_epochs, lr, teacher_forcing_ratio in zip(NUM_EPOCHS, LRS, TEACHER_FORCING_RATIOS):\n",
    "\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = model.train_one_epoch(train_loader, optimizer, criterion, 1)\n",
    "        val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weight('pretrained/lstm-improved-m128-h512-wn-lf3.pth')\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "\n",
    "    print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426af93",
   "metadata": {},
   "source": [
    "# 0.0678"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b560b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0460dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10  Lr: 0.0005  Teacher Forcing Ratio: 0\n",
      "Epoch 1: Train Loss = 0.03851746, Val Loss = 0.04302038, LR = 0.00009797\n",
      "Epoch 2: Train Loss = 0.03845023, Val Loss = 0.04247594, LR = 0.00009206\n",
      "Epoch 3: Train Loss = 0.03843306, Val Loss = 0.04284758, LR = 0.00008274\n",
      "Epoch 4: Train Loss = 0.03840928, Val Loss = 0.04230886, LR = 0.00007077\n",
      "Epoch 5: Train Loss = 0.03833015, Val Loss = 0.04259208, LR = 0.00005712\n",
      "Epoch 6: Train Loss = 0.03824751, Val Loss = 0.04174694, LR = 0.00004288\n",
      "Epoch 7: Train Loss = 0.03818129, Val Loss = 0.04170493, LR = 0.00002923\n",
      "Epoch 8: Train Loss = 0.03813975, Val Loss = 0.04163438, LR = 0.00001726\n",
      "Epoch 9: Train Loss = 0.03809372, Val Loss = 0.04156255, LR = 0.00000794\n",
      "Epoch 10: Train Loss = 0.03806962, Val Loss = 0.04157350, LR = 0.00000203\n",
      "Training complete. Best Val Loss: 0.041562553334881715\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-4\n",
    "NUM_EPOCHS = [20, 5, 5, 5, 5, 10][5:]\n",
    "LRS = [5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4][5:]\n",
    "TEACHER_FORCING_RATIOS = [1, 0.8, 0.6, 0.4, 0.2, 0][5:]\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=sum(NUM_EPOCHS) + 1)\n",
    "\n",
    "# best_val_loss = 0.14\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for num_epochs, lr, teacher_forcing_ratio in zip(NUM_EPOCHS, LRS, TEACHER_FORCING_RATIOS):\n",
    "\n",
    "    print(f'Epochs: {num_epochs}  Lr: {lr}  Teacher Forcing Ratio: {teacher_forcing_ratio}')\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = model.train_one_epoch(train_loader, optimizer, criterion, teacher_forcing_ratio)\n",
    "        val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weight('pretrained/lstm-decoder-only-m128-h512-l1')\n",
    "            # model.save_weight('pretrained/transformer-dm16-df32-nh4-e1-d1.pth')\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "\n",
    "    print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cb98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weight('pretrained/lstm-improved-m64-h256-l1-wn.pth')\n",
    "# model.load_weight('pretrained/lstm-base-m128-h512-wn.pth')\n",
    "# model.load_weight('pretrained/transformer-dm16-df32-nh4-e1-d1-wn.pth')\n",
    "model.load_weight('pretrained/lstm-decoder-only-m128-h512-l1')\n",
    "# model.load_weight('pretrained/lstm-base-m64-h256-wn-v2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5852b201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04232833784305731"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89725044",
   "metadata": {},
   "outputs": [],
   "source": [
    "9.35e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6344962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weight('pretrained/lstm-base-m64-h256-l1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67bf7b",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd58e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2258, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import GTSequenceDataset\n",
    "\n",
    "# SEQ_PATH = '../../Datasets/MOT20/val/MOT20-01/'\n",
    "# SEQ_PATH = '../../Datasets/MOT17/val/MOT17-04-FRCNN/'\n",
    "SEQ_PATH = '../../Datasets/DanceTrack/val/dancetrack0010///'\n",
    "SEQ_IN_LEN = 10\n",
    "SEQ_OUT_LEN = 2\n",
    "SEQ_TOTAL_LEN = 12\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "d = GTSequenceDataset.from_sequence(SEQ_PATH, seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN)\n",
    "# d = GTSequenceDataset.from_sequence(SEQ_PATH, seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, noise_prob=0.6, noise_coeff=2)\n",
    "sources = torch.tensor(d.sources).to(DEVICE)[:BATCH_SIZE]\n",
    "targets = torch.tensor(d.targets).to(DEVICE)[:BATCH_SIZE]\n",
    "\n",
    "o = model.inference(sources, targets, num_steps=targets.size(1) - 1)\n",
    "\n",
    "o[:, :, 0] *= d.image_width.item()\n",
    "o[:, :, 2] *= d.image_width.item()\n",
    "o[:, :, 1] *= d.image_height.item()\n",
    "o[:, :, 3] *= d.image_height.item()\n",
    "targets[:, :, 0] *= d.image_width.item()\n",
    "targets[:, :, 2] *= d.image_width.item()\n",
    "targets[:, :, 1] *= d.image_height.item()\n",
    "targets[:, :, 3] *= d.image_height.item()\n",
    "t = targets[:, 1:]\n",
    "sources[:, :, 0] *= d.image_width.item()\n",
    "sources[:, :, 2] *= d.image_width.item()\n",
    "sources[:, :, 1] *= d.image_height.item()\n",
    "sources[:, :, 3] *= d.image_height.item()\n",
    "\n",
    "index = 9\n",
    "# t[index], o[index]\n",
    "# f = (t[index] - o[index]).abs()[:, 3].mean()\n",
    "f = (t - o).abs().mean()\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7390cbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 10, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "685bf336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 294.3531,  811.7768,  413.6157, 1081.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c2c4581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 286.7705,  810.1767,  418.4162, 1081.0775]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75548378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.image_height.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e1c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4595, 0.3603, 0.5068, 0.6890],\n",
       "         [0.4916, 0.3975, 0.5206, 0.7048]],\n",
       "\n",
       "        [[0.4916, 0.3975, 0.5206, 0.7048],\n",
       "         [0.4530, 0.4065, 0.5024, 0.6868]],\n",
       "\n",
       "        [[0.4530, 0.4065, 0.5024, 0.6868],\n",
       "         [0.4324, 0.4058, 0.5474, 0.7003]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2288, 0.5286, 0.3329, 0.7175],\n",
       "         [0.2476, 0.5468, 0.3747, 0.6862]],\n",
       "\n",
       "        [[0.2476, 0.5468, 0.3747, 0.6862],\n",
       "         [0.2156, 0.5008, 0.3438, 0.7099]],\n",
       "\n",
       "        [[0.2156, 0.5008, 0.3438, 0.7099],\n",
       "         [0.2274, 0.5202, 0.3164, 0.7094]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
