{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import GTSequenceDataset\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "SEQ_IN_LEN = 30\n",
    "SEQ_OUT_LEN = 20\n",
    "SEQ_TOTAL_LEN = 50\n",
    "BATCH_SIZE = 1024\n",
    "STEPS = 4\n",
    "NOISE_COEFFICIENT = 0\n",
    "NOISE_PROB = 0\n",
    "NOISE_COEFFICIENT = 0.15\n",
    "NOISE_PROB = 0\n",
    "\n",
    "BASE_DIR = '../../Datasets/'\n",
    "# train_dataset = ConcatDataset([\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}DanceTrack/train'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT20/train'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT17/train'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "# ])\n",
    "# val_dataset = ConcatDataset([\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}DanceTrack/val'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT20/val'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "#     GTSequenceDataset.from_roots([f'{BASE_DIR}MOT17/val'], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB),\n",
    "# ])\n",
    "train_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}/SportsMOT/train',\n",
    "    f'{BASE_DIR}DanceTrack/train',\n",
    "    f'{BASE_DIR}MOT17/train',\n",
    "    f'{BASE_DIR}MOT20/train'\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB)\n",
    "\n",
    "val_dataset = GTSequenceDataset.from_roots([\n",
    "    f'{BASE_DIR}/SportsMOT/val',\n",
    "    f'{BASE_DIR}DanceTrack/val',\n",
    "    f'{BASE_DIR}MOT17/val',\n",
    "    f'{BASE_DIR}MOT20/val'\n",
    "# ], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=0, noise_prob=0)\n",
    "], seq_in_len=SEQ_IN_LEN, seq_out_len=SEQ_OUT_LEN, seq_total_len=SEQ_TOTAL_LEN, steps=STEPS, noise_coeff=NOISE_COEFFICIENT, noise_prob=NOISE_PROB)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1653683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_encoder import MotionTransformer\n",
    "from loss import LossFunction\n",
    "from torch import optim\n",
    "import math, torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "model = MotionTransformer(\n",
    "    input_dim=13,\n",
    "    output_dim=5,\n",
    "    d_model=256,\n",
    "    # d_model=512,\n",
    "    # nhead=16,\n",
    "    nhead=32,\n",
    "    num_layers=6,\n",
    "    dim_ff=512,\n",
    "    dropout=0.15,\n",
    ").to(DEVICE)\n",
    "criterion = LossFunction(loss1_coeff=1, loss2_coeff=0, loss3_coeff=0, loss4_coeff=0)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda925e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=1e-4,\n",
    "    eps=1e-8\n",
    ")\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#         optimizer,\n",
    "#         mode='min',\n",
    "#         factor=0.5,\n",
    "#         patience= 11,  # Reduce LR before early stopping\n",
    "#         verbose=True,\n",
    "#         min_lr=LR * 0.001\n",
    "#     )\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS + 1)\n",
    "best_val_loss = float(\"inf\")\n",
    "log_file = open('file.log', 'w')\n",
    "log_file.close()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss = model.train_one_epoch(train_loader, optimizer, criterion)\n",
    "    val_loss = model.evaluate(val_loader, criterion)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model.save_weight('pretrained/transformer-encoder-d256-ff512-nh32-1l-n3.pth')\n",
    "        # model.save_weight('pretrained/transformer-encoder-d512-ff512-2l.pth')\n",
    "\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\")\n",
    "    log_file = open('file.log', 'a')\n",
    "    log_file.write(f\"Epoch {epoch}: Train Loss = {train_loss:.8f}, Val Loss = {val_loss:.8f}, LR = {current_lr:.8f}\\n\")\n",
    "    log_file.close()\n",
    "\n",
    "print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
